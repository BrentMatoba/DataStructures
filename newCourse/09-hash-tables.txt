Hash Tables
"one data strucure to rule them all"

Outline:
    What is a Hash Table? and what is a hash function?
    Properties of hash functions?
    Discussion on collision resolution methods, in particular:
        separate chaining and open addressing
    Complexity analysis.
    Separate chaining implementation details
        Linked list approach overview
        separate chaining FAQ's
        Separate chaining source code
    Separate chaining HT source code.


    Open addresssing techniques. implemnetation details
        Linear probing
            what is linear probing?
            chaos with cycles
            linear probing insertion Examples
            table resizing and updating values
        Quadratic probing   
            what is quadratic probing?
            problem siwth probing sequence cycles
            different ways to quadratically problem
            inserting/resize Examples
    
    Double Hashing
        Whatg is double hashing? How does it work?
        Chaos with cycles
        Constructin ga new hash function 
            Universal hash functions
        Inserting/resize example

        Removing elements
            Solution using tombstones
            Lazy deletion/relocation
            lots of Examples


What is a hash table?
     A hash table (HT) is a data strucutre that provides a mapping from keys to values using 
     a technique called hashing. (ALSO CALLED DICTIONARY)
     Key value pairs, keys must be unique, but values can be repeated.
     
     HTs are often used to track item frequencies. For instance, counting the number of times a 
     word appears in a given text.
    
    A hash function H(x) is a function that maps a key "x" to a whole number in a fixed range.
    

    We can also define hash functions for arbitray objects such as strings, lits, tuples,
    multi data objects, etc...

    for a string s let H(s) be a hash function defined below ehre ASCII(x) returns tot he ASCII value of the character x

    If H(x) == H(y) then objects x and y might be equal, but if H(x) != H(y), then x and y are certainly not equal./

    Q: How can weuse this to our advantage to speedup object comparisonS?
    A: This means that instead of comparing x and y directly, a smarter approach is to first compare their
    hash values, and only if the hash values match do we need to explicitly compare x and y.

Properties of Hash Functions:
    Consider the problem of trying to determine if two very large files have the same contents.
    If we precomputed H(fil1) and H(file2) first we should compare those hash values since comparing
    hash values is O(1)! If possible, we do not want to copen either of the fiels directly. comparing
    their  contents can be very slow, although we may have to if H(file1) == H(file2)

        *note: Hash functions for files are more sophisticated that those used for hashtables. instead
        for files we use what are called cyptographic hash functions also called checksums.
    
    Another proerty of Hash Functions
        Hash functions H(x) MUST be deterministic.
            THis means that if H(x) == y, then H(x) must always produce y and never another value.
            This may seem ohvious, but is critical to the functionality of a hash function.

        WE try very hard to make uniform hash functions to minimize the number of hash colisions
        A hash colision is when two bojects x, y hash to the same value.

        We are now able to answer a centrla questions about the types of keys we are allowed to use
        in our hashtables
        Q: WHat makes a key of Type T hashable?
        A: Since we are going to use hash functions in the implementation of our hash table we need
        our hash functions to be deterministic.
        To enforcethis behavior, we demand that the keys used in our hash table are immutable data types.
        Hence, if a key of some type T is immutable, and we have a hash function H(k) defined for all
        keys k of type T then we say a key of type Tis hashable.

How does a hash table work?
    Ideally we would like to have a very fast insertion, lookup and removal time for the data we are 
    placing within our hash table. Remarkably, we can achieve all this in O(1) time using a hash
    function as a way to index into a hash table.

    *The constant time behavior attributed to hash tables is only true if you have a good uniform hash function!


    What do we do if there is a hash collision?
    A: We use on of many hash collision resolution techniques to handle this, the two more popular ones
    are separate chaining a open addressing.

    Separate chaining deals with hash collisions by maintaing a data structure (usually a linked list)
    to hold all the different values which hashed to a particular value.

    Open addressing: deals with hash collisions by finding anohter place within the hash table for the object
    to go by offsettting it from the position to which it hashed to.


Time Complexity:
    Insertion: Average: O(1), Worst O(n)
    Removal: Average: O(1), Worst O(n)
    Search: Average: O(1), Worst O(n)

    The constant time behavior is attributed to hash tables is only true if you have a good uniform
    hash function!


What is separate chaining:
    Separate chaining is one of many strategies to deal with has collisions by maintaing a data structure
    (usually a linked list) to hold all the different values hwich hased to a particular value.

    *NOTE: The data strucutre used to cache the items which hjased to a particular value is not
    limited to a linked list. Some implementations use oe or a mixture of: arrays, binary trees,
    self banacing trees and etc...

Hash Table FAQs
    Q: How do I maintain O(1) insertion and lookup time complexity one my HT gets really full and I have
    long linked list chains?
    A: Once the HT ocntains a lot of elements you should cratae a new HT with a larger capacity and rehash all
    the items inside the old HT and disperate them throughought the new HT at different locations.

    Q: How do I remove key-value pairs from my HT?
    A: Apply the same procedure as doing a lookup for a key, but this time instead of returning the value associated
    with they key, remove the node in the linked list structure.

    Q: Can I use another data structure ot model the bucket behavior required for the separate chaining method?
    A: Of course! Common data strucutres used instead of alinked list include: arrays, binary t rees, self balanacing trees,
    etc... You can even go with a hybrid approach like java's HashMap. However, note that some of these are much more memory
    intensive and complex to implement than a simple linked list which is why they may be less popular.


Hash Table Open Addressing
    The goal of the Hash Table is to construct a mapping from keys to values.
    Keys must be hashable and we need a hash function taht converts keys to whole numbers.
    We use the hash function defined on our key set to index into an array ( the hash table.)
    Hash functions are not perfect, there fore sometimes two keys, k1, k2, hash to the same value.
    When this happens, we have a hash collision.
    Open addresssing is a way to solve this issue.

    When using open addressing as a collision resolution technique the key-value pairs are stored in teh table(array)
    itself as opposed to a data strucutre lik ein separate chaining.

    THis means we need to care a great deal about the size of our hash table and how many elements are currenlty in the table.
    Load factor = items in table/size of table.

    The O(1) constant time bheavior attributed to hash tables assumes the load factor is kept below a certain threshold value.
    This means once the load factor is above the threshold, we need to grow the table size (ideally exponentially, e.g. double the size.)

Open addressing main idea:
    When we want to insert the key-value pair into the hash table, we hash the key and obtain an original position
    for where this key-value pair belongs. 

    If the position our key hashed to is occuiped, we try another position in the hash table by offsetting the current
    position subject to a probing sequence P(x). We keep doing this until an unoccupied slot is found.
    
    There are an infinite amount of probing sequences you can come up with
    Linear probing:
        P(x) = ax + b where a, b are constants

    Quadratic probing:
        P(x) = ax^2 + bx + c where a, b, c are constants.
    
    DOuble Hasing:
        P(k,x) = x*H^2(k) where H^2(k) is a secondarfy hash funciton.
    
    Pseudo random number geneerator:
    OP(k,x) = x*RNG(H(k), x) where RNG is a random number generator function seeded with H(k).
